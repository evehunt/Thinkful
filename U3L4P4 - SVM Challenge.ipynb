{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier evaluation functions from unit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your confusion matrix and calculate sensitivity and specificity here.\n",
    "\n",
    "def evaluate(y_pred, target):\n",
    "    conf_data = {'target':target, 'y_pred':y_pred}\n",
    "    conf_data = pd.DataFrame(data=conf_data)\n",
    "    \n",
    "    true_negatives = conf_data.loc[(conf_data['target'] == False) & (conf_data['y_pred'] == False)].shape[0]\n",
    "    type_II = conf_data.loc[(conf_data['target'] == True) & (conf_data['y_pred'] == False)].shape[0] # False Negatives\n",
    "    total_negatives = true_negatives + type_II\n",
    "    \n",
    "    true_positives = conf_data.loc[(conf_data['target'] == True) & (conf_data['y_pred'] == True)].shape[0]\n",
    "    type_I = conf_data.loc[(conf_data['target'] == False) & (conf_data['y_pred'] == True)].shape[0] # False Positives\n",
    "    total_positives = true_positives + type_I\n",
    "    \n",
    "    total_positives = conf_data.loc[(conf_data['target'] == True)].shape[0]\n",
    "    total_negatives = conf_data.loc[(conf_data['target'] == False)].shape[0]\n",
    "    \n",
    "    sensitivity = round(true_positives/total_positives*100,2)\n",
    "    specificity = round(true_negatives/total_negatives*100,2)\n",
    "    \n",
    "    confusion_matrix = np.array([[true_negatives, type_II],\n",
    "                                 [type_I, true_positives]])\n",
    "   \n",
    "    output = {'n':conf_data.shape[0],\n",
    "              'Confusion Matrix':confusion_matrix,\n",
    "              'Type I':type_I,\n",
    "              'Type II':type_II,\n",
    "              'Sensitivity':sensitivity,\n",
    "              'Specificity':specificity}\n",
    "    \n",
    "    return output\n",
    "\n",
    "def cross_validation(dataframe,\n",
    "                     model,\n",
    "                     k, # number of folds\n",
    "                     target, # string – target column name within dataframe\n",
    "                     variables): # list – X values within dataframe\n",
    "\n",
    "    frames = np.array_split(dataframe, k)     # Split frame into K folds    \n",
    "    label = 0     # Number the folds for easier reading\n",
    "    folds = {} # Create an empty list to hold outputs for each fold\n",
    "    \n",
    "    # Create a dataframe to serve as a final output\n",
    "\n",
    "    # Create dictionary to house outputs\n",
    "    summary_dict = {'fold_id':[], 'fold_size':[], 'mislabeled':[], 'percent_mislabeled':[], \n",
    "                    'sensitivity':[], 'specificity':[], 'type_i':[], 'type_ii':[]}\n",
    "    \n",
    "    for f in frames:\n",
    "        \n",
    "        # Define inputs\n",
    "        label = label + 1 # Update the label number\n",
    "        summary_dict['fold_id'].append(label)\n",
    "        \n",
    "        test_data = f[variables] # Create a frame to store test data in\n",
    "        \n",
    "        # Get y_pred\n",
    "        y_pred = model.predict(test_data) # Classify, storing the result in a new variable.\n",
    "        f['y_pred'] = y_pred # Add it to our fold\n",
    "\n",
    "        # Evaluate for outputs\n",
    "        evaluation = evaluate(f['y_pred'], f[target])\n",
    "\n",
    "        # Append dictionary\n",
    "        summary_dict['fold_size'].append(evaluation['n'])\n",
    "        summary_dict['mislabeled'].append((f[target] != f['y_pred']).sum())\n",
    "        summary_dict['percent_mislabeled'].append(round((f[target] != f['y_pred']).sum()/evaluation['n'],2))\n",
    "        summary_dict['sensitivity'].append(evaluation['Sensitivity'])\n",
    "        summary_dict['specificity'].append(evaluation['Specificity'])\n",
    "        summary_dict['type_i'].append(evaluation['Type I']) \n",
    "        summary_dict['type_ii'].append(evaluation['Type II'])\n",
    "\n",
    "    return pd.DataFrame(summary_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "_Transform this regression problem into a binary classifier and clean up the feature set. You can choose whether or not to include nutritional information, but try to cut your feature set down to the 30 most valuable features._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/guest/Dropbox/Education/Thinkful/Unit 3 - Deeper into supervised learning/Lesson 4 - Support Vector Machines/epicurious-recipes-with-rating-and-nutrition/epi_r.csv'\n",
    "raw_data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a cutoff for high vs. low scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1P8HkYwnBe53RXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cdf49e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median value for recipe rating is 4.375\n",
      "There are 10738 observations below 4, and 9314 above or equal to it.\n"
     ]
    }
   ],
   "source": [
    "raw_data.rating.hist(bins=10)\n",
    "plt.title('Histogram of Recipe Ratings')\n",
    "plt.show()\n",
    "\n",
    "proposed_cutoff = 4\n",
    "below = raw_data['rating'][raw_data['rating'] >= proposed_cutoff].shape[0]\n",
    "above = raw_data['rating'][raw_data['rating'] < 4].shape[0]\n",
    "\n",
    "print('The median value for recipe rating is {}'.format(raw_data['rating'].median()))\n",
    "print('There are {} observations below {}, and {} above or equal to it.'.format(below, proposed_cutoff, above))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I'm choosing 4 as the cut point for the binary rating variable. It's near the numeric center of the set, and it's my subjective opinion that a rating of 4 or above is \"pretty good\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = raw_data.copy()\n",
    "all_data['rating_hilo'] = np.where(all_data['rating'] >= 4, 1, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEXCAYAAABlI9noAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a14bfe630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='rating_hilo', data=all_data)\n",
    "plt.title('Histogram of Recipe Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I have two options here – I can either cut out the nulls in the nutrition data by dropping their rows (which will deprive our model of about a quarter of our observations), or by removing the nutritional information columns altogether (which will deprive our model of the 5 most interesting features). I have a hunch that the nutrition data is probably valuable, but I can check that assumption by running decision trees on both datasets (this data is small enough that they shouldn't take too long) and comparing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n with rows dropped: 15864\n",
      "n with columns dropped: 20052\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows\n",
    "rows_dropped = all_data.copy().drop(['rating','title'], axis=1).dropna(axis=0)\n",
    "print('n with rows dropped: {}'.format(rows_dropped.shape[0]))\n",
    "\n",
    "# Drop the columns\n",
    "cols_dropped = all_data.copy().drop(['rating', 'title', 'calories', 'protein', 'fat', 'sodium'], axis=1)\n",
    "print('n with columns dropped: {}'.format(cols_dropped.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### With the rows dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X & Y\n",
    "rX = pd.DataFrame(rows_dropped.drop(['rating_hilo'], axis=1))\n",
    "rY = rows_dropped['rating_hilo']\n",
    "\n",
    "# Initialize and train the tree\n",
    "row_rfc = RandomForestClassifier(max_features=30, criterion='entropy')\n",
    "row_rfc.fit(rX, rY)\n",
    "score = cross_val_score(row_rfc, rX, rY, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree model\n",
      "Mean accuracy across 10 folds: 0.63\n",
      "Variance: 0.0001\n",
      "\n",
      "** Rows dropped performance across 10 folds\n",
      "      percent_mislabeled  sensitivity  specificity\n",
      "mean                0.01        98.38        99.49\n",
      "std                 0.00         0.31         0.24\n"
     ]
    }
   ],
   "source": [
    "# Cross validate\n",
    "print('Decision tree model')\n",
    "print('Mean accuracy across 10 folds: {}'.format(round(score.mean(),2)))\n",
    "print('Variance: {}'.format(round(score.std()**2,4)))\n",
    "\n",
    "\n",
    "print('\\n** Rows dropped performance across 10 folds')\n",
    "print(cross_validation(rows_dropped, row_rfc, 10, 'rating_hilo', list(rX)).describe().round(2)[['percent_mislabeled','sensitivity','specificity']][1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### With the columns dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cX = pd.DataFrame(cols_dropped.drop(['rating_hilo'], axis=1))\n",
    "cY = cols_dropped['rating_hilo']\n",
    "\n",
    "# Initialize and train our tree.\n",
    "col_rfc = RandomForestClassifier(max_features=30, criterion='entropy')\n",
    "col_rfc.fit(cX, cY)\n",
    "score = cross_val_score(col_rfc, cX, cY, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy across 10 folds: 0.63\n",
      "Variance: 0.0002\n",
      "\n",
      "** Columns dropped prediction performance across 10 folds\n",
      "      percent_mislabeled  sensitivity  specificity\n",
      "mean                0.01        98.08        99.34\n",
      "std                 0.00         0.74         0.35\n"
     ]
    }
   ],
   "source": [
    "print('Mean accuracy across 10 folds: {}'.format(round(score.mean(),2)))\n",
    "print('Variance: {}'.format(round(score.std()**2,4)))\n",
    "\n",
    "print('\\n** Columns dropped prediction performance across 10 folds')\n",
    "print(cross_validation(cols_dropped, col_rfc, 10, 'rating_hilo', list(cX)).describe().round(2)[['percent_mislabeled','sensitivity','specificity']][1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Those look nearly identical.  Let's have a closer look at feature importance between the two models to see how much the nutrition features are contributing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calories</td>\n",
       "      <td>0.060640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>protein</td>\n",
       "      <td>0.044627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fat</td>\n",
       "      <td>0.049180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sodium</td>\n",
       "      <td>0.060632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  feature_importance\n",
       "0  calories            0.060640\n",
       "1   protein            0.044627\n",
       "2       fat            0.049180\n",
       "3    sodium            0.060632"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowdr_feature_importance = {'feature':list(rX),'feature_importance':list(row_rfc.feature_importances_)}     \n",
    "rowdr_feature_importance = pd.DataFrame(rowdr_feature_importance)\n",
    "\n",
    "print('Rows dropped model:')\n",
    "rowdr_feature_importance[rowdr_feature_importance['feature_importance'] >= .01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It looks as though the nutrition features are far and away the most important in this model. How does that compare with the importance of features in the columns dropped model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>quick &amp; easy</td>\n",
       "      <td>0.011354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>summer</td>\n",
       "      <td>0.010624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>winter</td>\n",
       "      <td>0.011185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  feature_importance\n",
       "502  quick & easy            0.011354\n",
       "597        summer            0.010624\n",
       "661        winter            0.011185"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldr_feature_importance = {'feature':list(cX),'feature_importance':list(col_rfc.feature_importances_)}     \n",
    "coldr_feature_importance = pd.DataFrame(coldr_feature_importance)\n",
    "\n",
    "print('Columns dropped model:')\n",
    "coldr_feature_importance[coldr_feature_importance['feature_importance'] >= .01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The nutrition columns are more impactful than any other features in the dataset. Let's move forward with the model that retains them and drops null rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(rows_dropped[['calories', 'protein', 'fat', 'sodium']])\n",
    "Y = rows_dropped['rating_hilo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr2 = SVR()\n",
    "svr2.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13313117, 0.10589892, 0.10130665, 0.11739195, 0.1192018 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svr2, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This model still sucks! Maybe I should try a different feature selection method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features my random forests chose didn't do me a lot of good. I'm going to make an attempt at feature selection via select K best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 30 Features:\n",
      "['calories', 'protein', 'fat', 'sodium', 'alcoholic', 'bitters', 'bon appétit', 'christmas', 'cocktail', 'cocktail party', 'dinner', 'drink', 'fall', 'gin', 'goat cheese', 'grill', 'grill/barbecue', 'harpercollins', 'house & garden', 'low carb', 'pasta', 'peanut free', 'quick & easy', 'roast', 'soy free', 'spirit', 'stuffing/dressing', 'thanksgiving', 'vegan', 'turkey']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "selector = SelectKBest(chi2, k=30)\n",
    "selector.fit(rX,rY)\n",
    "\n",
    "rd_k_best = rows_dropped.copy()\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "best_30 = list(rd_k_best[rd_k_best.columns[idxs_selected]].head())\n",
    "\n",
    "print('Best 30 Features:')\n",
    "print(best_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(rows_dropped[best_30])\n",
    "Y = rows_dropped['rating_hilo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr3 = SVR()\n",
    "svr3.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0740986 , 0.04969971, 0.06998488, 0.08906999, 0.08302533])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svr3, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got pretty good lift here overall, but the model is still overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 30 Features:\n",
      "['calories', 'protein', 'fat', 'sodium', 'bon appétit', 'drink', 'gin', 'house & garden', 'roast', 'thanksgiving']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "selector = SelectKBest(chi2, k=10)\n",
    "selector.fit(rX,rY)\n",
    "\n",
    "rd_k_best = rows_dropped.copy()\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "best_10 = list(rd_k_best[rd_k_best.columns[idxs_selected]].head())\n",
    "\n",
    "print('Best 30 Features:')\n",
    "print(best_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(rows_dropped[best_10])\n",
    "Y = rows_dropped['rating_hilo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr4 = SVR()\n",
    "svr4.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11869094, 0.08882676, 0.09069588, 0.11076892, 0.11105956])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svr4, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The second iteration is the best – less overfit than the third. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
